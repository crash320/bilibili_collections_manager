import requests
import os
import json
import re
import time
import random
import hashlib
import base64
import hmac
import urllib.parse
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from functools import partial
from utils import load_config, setup_logging, retry_on_failure, DownloadQueue
import logging

def setup_logging(config):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºlogsç›®å½•
    log_dir = os.path.join(os.path.dirname(__file__), 'logs')
    os.makedirs(log_dir, exist_ok=True)
    
    # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼Œæ ¼å¼ï¼šbili_collect_YYYY-MM-DD_HH-MM-SS.log
    timestamp = time.strftime('%Y-%m-%d_%H-%M-%S')
    log_file = os.path.join(log_dir, f'bili_collect_{timestamp}.log')
    
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger('BilibiliCollector')
    logger.setLevel(logging.INFO)
    
    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ - è®°å½•æ‰€æœ‰æ—¥å¿—
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨ - ä½¿ç”¨å½©è‰²è¾“å‡ºå¹¶ç®€åŒ–æ ¼å¼
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # å®šä¹‰å½©è‰²è¾“å‡ºæ ¼å¼
    class ColorFormatter(logging.Formatter):
        """è‡ªå®šä¹‰å½©è‰²æ—¥å¿—æ ¼å¼å™¨"""
        
        grey = "\x1b[38;21m"
        blue = "\x1b[34;21m"
        yellow = "\x1b[33;21m"
        red = "\x1b[31;21m"
        bold_red = "\x1b[31;1m"
        reset = "\x1b[0m"

        def __init__(self):
            super().__init__()
            self.FORMATS = {
                logging.DEBUG: self.grey + "ğŸ” %(message)s" + self.reset,
                logging.INFO: self.blue + "â„¹ï¸ %(message)s" + self.reset,
                logging.WARNING: self.yellow + "âš ï¸ %(message)s" + self.reset,
                logging.ERROR: self.red + "âŒ %(message)s" + self.reset,
                logging.CRITICAL: self.bold_red + "ğŸ†˜ %(message)s" + self.reset
            }

        def format(self, record):
            log_fmt = self.FORMATS.get(record.levelno)
            formatter = logging.Formatter(log_fmt)
            return formatter.format(record)

    console_handler.setFormatter(ColorFormatter())
    
    # æ·»åŠ å¤„ç†å™¨åˆ°è®°å½•å™¨
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    # è®°å½•å¯åŠ¨ä¿¡æ¯
    logger.info('='*50)
    logger.info('ç¨‹åºå¯åŠ¨')
    logger.info(f'é…ç½®ä¿¡æ¯å·²ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶')
    logger.info('='*50)
    
    # è¯¦ç»†é…ç½®ä¿¡æ¯åªå†™å…¥æ–‡ä»¶
    file_handler.handle(
        logging.LogRecord(
            'BilibiliCollector', logging.INFO, '', 0,
            f'é…ç½®ä¿¡æ¯: {json.dumps(config, ensure_ascii=False, indent=2)}',
            (), None
        )
    )
    
    return logger

class BilibiliCollector:
    def __init__(self):
        self.config = load_config()
        self.logger = setup_logging(self.config)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers = self.headers
        self.download_queue = DownloadQueue(self.config['download']['max_concurrent'])

    def login(self):
        """ç™»å½•Bç«™è·å–cookie"""
        os.startfile(self.config['edge']['debug_shortcut'])
        options = Options()  # å¾—åˆ°edgeçš„è®¾ç½®
        options.add_experimental_option(
            "debuggerAddress", f"127.0.0.1:{self.config['edge']['debug_port']}")  # é…ç½®æµè§ˆå™¨çš„ç«¯å£åœ°å€
        # options.add_experimental_option('excudeSwitches',['enable-automation'])
        driver = webdriver.Edge(service=Service(
            self.config['edge']['driver_path']), options=options)  # æµè§ˆå™¨é©±åŠ¨çš„æ”¾ç½®åœ°å€
        
        driver.get("https://passport.bilibili.com/login")
        time.sleep(3)
        # ç­‰å¾…ç™»å½•å®Œæˆ
        WebDriverWait(driver, 300).until(EC.url_contains("https://www.bilibili.com/"))
        cookies = driver.get_cookies()
        for cookie in cookies:
            self.session.cookies.set(cookie['name'], cookie['value'])
        driver.quit()

    def get_collection_list(self, mid):
        """è·å–ç”¨æˆ·æ”¶è—å¤¹åˆ—è¡¨"""
        url = f"https://api.bilibili.com/x/v3/fav/folder/created/list-all?up_mid={mid}"
        response = self.session.get(url)
        self.logger.info(f"get collection_list: {url}")
        return response.json()

    def get_collection_content(self, media_id, pn=1):
        """è·å–æ”¶è—å¤¹å†…å®¹"""
        url = f"https://api.bilibili.com/x/v3/fav/resource/list?media_id={media_id}&pn={pn}&ps=20"
        response = self.session.get(url)
        self.logger.info(f"get collection_content: {url}")
        return response.json()

    def download_cover(self, url, aid):
        """ä¸‹è½½è§†é¢‘å°é¢"""
        response = self.session.get(url)
        self.logger.info(f"get download_cover: {url}")
        if not os.path.exists('covers'):
            os.makedirs('covers')
        with open(f'covers/{aid}.jpg', 'wb') as f:
            f.write(response.content)

    def get_comments(self, aid):
        """è·å–è§†é¢‘è¯„è®º"""
        try:
            url = f"https://api.bilibili.com/x/v2/reply?pn=1&type=1&oid={aid}"
            response = self.session.get(url)
            if response.status_code != 200:
                self.logger.error(f"è·å–è¯„è®ºå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return {"code": -1, "message": "è¯·æ±‚å¤±è´¥", "data": []}
            
            # æ£€æŸ¥å“åº”çŠ¶æ€å’Œå†…å®¹
            if not response.ok:
                self.logger.warning(f"è·å–è¯„è®ºè¯·æ±‚å¤±è´¥: {response.status_code}")
                return {"code": response.status_code, "message": "è¯·æ±‚å¤±è´¥", "data": []}

            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºç©º
            content = response.text.strip()
            if not content:
                self.logger.error("è·å–è¯„è®ºå“åº”ä¸ºç©º")
                return {"code": -1, "message": "å“åº”ä¸ºç©º", "data": []}
            
            # å°è¯•è§£æ JSON
            try:
                data = response.json()
                if data.get('code') == -404:  # è¯„è®ºå·²å…³é—­
                    return {"code": -404, "message": "è¯„è®ºåŠŸèƒ½å·²å…³é—­", "data": []}
                elif data.get('code') != 0:
                    self.logger.error(f"è·å–è¯„è®ºAPIè¿”å›é”™è¯¯: {data.get('message')}")
                    return {"code": data.get('code'), "message": data.get('message'), "data": []}
                return data
            except json.JSONDecodeError as e:
                self.logger.warning(f"è¯„è®ºJSONè§£æå¤±è´¥: {str(e)}, å†…å®¹: {content[:100]}")
                return {"code": -1, "message": "JSONè§£æå¤±è´¥", "data": []}
        except Exception as e:
            self.logger.warning(f"è·å–è¯„è®ºå¼‚å¸¸: {str(e)}")
            return {"code": -1, "message": str(e), "data": []}

    def get_danmaku(self, cid):
        """è·å–è§†é¢‘å¼¹å¹•"""
        try:
            url = f"https://api.bilibili.com/x/v1/dm/list.so?oid={cid}"
            response = self.session.get(url)

            # å¤„ç†ç‰¹æ®ŠçŠ¶æ€ç 
            if response.status_code == 412:
                return "<i>å¼¹å¹•è·å–è¢«æ‹¦æˆªï¼Œéœ€è¦éªŒè¯</i>"
            elif response.status_code != 200:
                return f"<i>è·å–å¼¹å¹•å¤±è´¥: {response.status_code}</i>"
            elif response.status_code != 200:
                self.logger.error(f"è·å–å¼¹å¹•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return "<i>å¼¹å¹•è·å–å¤±è´¥</i>"
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºç©º
            if not response.content:
                self.logger.error("è·å–å¼¹å¹•å“åº”ä¸ºç©º")
                return "<i>å¼¹å¹•å†…å®¹ä¸ºç©º</i>"
            
            return response.content.decode('utf-8')
        except Exception as e:
            return f"<i>è·å–å¼¹å¹•å‡ºé”™: {str(e)}</i>"

    @retry_on_failure(max_retries=3, delay=2)
    def download_video(self, aid, bvid, video_path):
        """ä¸‹è½½è§†é¢‘åˆ°æŒ‡å®šè·¯å¾„"""
        try:
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
            if os.path.exists(video_path):
                if os.path.getsize(video_path) > 1024 * 1024:
                    self.logger.info(f"è§†é¢‘å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œè·³è¿‡ä¸‹è½½: {video_path}")
                    return
                else:
                    #æ‰“å¼€è§†é¢‘æŸ¥çœ‹æ˜¯å¦å¯ä»¥è§£ç 
                    try:
                        import ffmpeg
                        ffmpeg.probe(video_path)
                        self.logger.info(f"è§†é¢‘å·²å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œè·³è¿‡ä¸‹è½½: {video_path}")
                        return
                    except Exception as e:
                        self.logger.warning(f"è§†é¢‘å·²å­˜åœ¨ä½†æ–‡ä»¶å¤§å°å¼‚å¸¸ï¼Œåˆ é™¤å¹¶é‡æ–°ä¸‹è½½: {video_path}")
                        os.remove(video_path)

            # è·å–cid
            cid_url = f"https://api.bilibili.com/x/web-interface/view?bvid={bvid}"  # ä½¿ç”¨bvidæ›¿ä»£aid
            cid_response = self.session.get(cid_url, timeout=self.config['request']['timeout'])
            cid_data = cid_response.json()
            if cid_data['code'] != 0:
                raise Exception(f"è·å–cidå¤±è´¥: {cid_data['message']}")
            
            cid = cid_data['data']['cid']
            
            # è·å–è§†é¢‘ä¸‹è½½åœ°å€
            quality = self.config['download']['video_quality']
            # æ›´æ–°è¯·æ±‚URLå’Œå‚æ•°
            url = f"https://api.bilibili.com/x/player/playurl"
            params = {
                'avid': aid,
                'bvid': bvid,
                'cid': cid,
                'qn': quality,
                'fnval': 16,  # æ”¯æŒdashæ ¼å¼
                'fnver': 0,
                'fourk': 1
            }
            
            # æ›´æ–°è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Referer': f'https://www.bilibili.com/video/{bvid}',
                'Origin': 'https://www.bilibili.com',
                'Accept': '*/*',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept-Language': 'zh-CN,zh;q=0.9',
                'Cookie': '; '.join([f'{k}={v}' for k, v in self.session.cookies.items()])
            }
            # ç¦ç”¨ä»£ç†
            original_proxies = self.session.proxies
            self.session.proxies = {}

            try:    
                response = self.session.get(url, params=params, headers=headers, timeout=30)
                
                self.logger.info(f"get download_video: {url}")

                if response.status_code != 200:
                    raise Exception(f"è·å–è§†é¢‘åœ°å€å¤±è´¥: {response.status_code}")
                
                video_data = response.json()
                
                self.logger.info(f"get download_video: {video_data}")
                
                # è·å–æœ€é«˜è´¨é‡çš„è§†é¢‘åœ°å€
                if 'data' in video_data and 'dash' in video_data['data']:
                    # DASHæ ¼å¼
                    video_url = video_data['data']['dash']['video'][0]['baseUrl']
                else:
                    # ä¼ ç»Ÿæ ¼å¼
                    video_url = video_data['data']['durl'][0]['url']
                
                # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                headers['Range'] = 'bytes=0-'  # æ·»åŠ Rangeå¤´
                temp_path = f"{video_path}.tmp"
                downloaded_size = 0
            
                if os.path.exists(temp_path):
                    downloaded_size = os.path.getsize(temp_path)
                    headers['Range'] = f'bytes={downloaded_size}-'
                
                # ä½¿ç”¨è¾ƒå°çš„chunk_sizeä»¥æé«˜ç¨³å®šæ€§
                chunk_size = 512 * 1024  # 512KB
                response = self.session.get(video_url, stream=True, headers=headers, timeout=60)
            
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code not in [200, 206]:
                    raise Exception(f"ä¸‹è½½è§†é¢‘å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
                # è·å–æ€»å¤§å°
                total_size = int(response.headers.get('content-length', 0)) + downloaded_size
                
                if total_size < 1024 * 1024:  # å°äº1MBå¯èƒ½æ˜¯é”™è¯¯å“åº”
                    raise Exception("è§†é¢‘å¤§å°å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯æ— æ•ˆå“åº”")
                
                mode = 'ab' if downloaded_size > 0 else 'wb'
                with open(temp_path, mode) as f:
                    for chunk in response.iter_content(chunk_size=self.config['download']['chunk_size']):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            self.logger.info(f"ä¸‹è½½è¿›åº¦: {downloaded_size}/{total_size} ({(downloaded_size/total_size)*100:.2f}%)")
            
                # ä¸‹è½½å®Œæˆåæ£€æŸ¥æ–‡ä»¶å¤§å°
                if abs(os.path.getsize(temp_path) - total_size) > total_size * 0.01:
                    raise Exception("æ–‡ä»¶å¤§å°ä¸åŒ¹é…ï¼Œä¸‹è½½å¯èƒ½ä¸å®Œæ•´")
                
                # ä¿®æ”¹æ–‡ä»¶é‡å‘½åé€»è¾‘
                if os.path.exists(video_path):
                    os.remove(video_path)  # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                os.rename(temp_path, video_path)
                self.logger.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {video_path}")
            finally:
                # æ¢å¤ä»£ç†
                self.session.proxies = original_proxies
            
        except Exception as e:
            self.logger.error(f"ä¸‹è½½è§†é¢‘å¤±è´¥ {bvid}: {str(e)}")
            # æ¸…ç†å¯èƒ½çš„ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(f"{video_path}.tmp"):
                os.remove(f"{video_path}.tmp")
            raise

    def save_info(self, data):
        """ä¿å­˜è§†é¢‘ä¿¡æ¯"""
        if not os.path.exists('info'):
            os.makedirs('info')
        with open(f'info/{data["aid"]}.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def process_video(self, cache_dir, item):
        """å¤„ç†å•ä¸ªè§†é¢‘çš„æ‰€æœ‰ä¿¡æ¯"""
        try:
            video_id = item['id']
            bvid = item['bvid']
            title = item['title']
        
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦å¯è®¿é—®
            check_url = f"https://api.bilibili.com/x/web-interface/view?bvid={bvid}"
            check_response = self.session.get(check_url)
            self.logger.info(f"get check_url: {check_url}")
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if check_response.status_code != 200:
                if isinstance(check_response.json(), dict) and "message" in check_response.json():
                    self.logger.warning(f"è§†é¢‘ä¸å¯è®¿é—®ï¼Œè·³è¿‡: é”™è¯¯ä¿¡æ¯ {check_response.json()['message']} æ ‡é¢˜ {title}")
                else:
                    self.logger.warning(f"è§†é¢‘ä¸å¯è®¿é—®ï¼Œè·³è¿‡: é”™è¯¯ä¿¡æ¯ {check_response} æ ‡é¢˜ {title}")
                return
            
            video_cache_dir = os.path.join(cache_dir, str(video_id))
            os.makedirs(video_cache_dir, exist_ok=True)

            # ç®€åŒ–çš„ç»ˆç«¯è¾“å‡º
            self.logger.info(f"å¤„ç†è§†é¢‘: {title[:20]}{'...' if len(title) > 20 else ''}")
            
            video_data = {
                'title': title,
                'id': video_id,
                'bvid': bvid,
                'desc': item.get('intro', ''),
                'cover': item['cover']
            }
            
            try:
                # ä¸‹è½½å°é¢
                cover_path = os.path.join(video_cache_dir, f'cover.jpg')
                if not os.path.exists(cover_path):
                    self.logger.debug(f"ä¸‹è½½å°é¢: {video_id}")  # é™ä½æ—¥å¿—çº§åˆ«
                    self.logger.info(f"ä¸‹è½½è§†é¢‘å°é¢: {video_id}")
                    self.logger.info(f"get item['cover']: {item['cover']}")
                    response = self.session.get(item['cover'])
                    if response.status_code == 200:
                        with open(cover_path, 'wb') as f:
                            f.write(response.content)
                    else:
                        self.logger.error(f"ä¸‹è½½å°é¢å¤±è´¥: {response.status_code}")
            except Exception as e:
                self.logger.error(f"ä¸‹è½½å°é¢å¤±è´¥: {str(e)}")
            
            # è·å–è¯„è®ºï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
            try:
                comments_path = os.path.join(video_cache_dir, 'comments.json')
                if not os.path.exists(comments_path):
                    self.logger.debug(f"è·å–è¯„è®º: {video_id}")  # é™ä½æ—¥å¿—çº§åˆ«
                    comments = self.get_comments(video_id)
                    # åªæœ‰åœ¨æˆåŠŸè·å–è¯„è®ºæ—¶æ‰å†™å…¥æ–‡ä»¶
                    if comments and comments.get('code') == 0 and isinstance(comments, dict):
                        with open(comments_path, 'w', encoding='utf-8') as f:
                            json.dump(comments, f, ensure_ascii=False, indent=4)
                else:
                    # è¯»å–ç°æœ‰è¯„è®ºæ–‡ä»¶
                    try:
                        with open(comments_path, 'r', encoding='utf-8') as f:
                            content = f.read().strip()
                            if content:  # ç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º
                                comments = json.loads(content)
                            else:
                                comments = {"code": -1, "message": "ç¼“å­˜æ–‡ä»¶ä¸ºç©º", "data": []}
                    except (json.JSONDecodeError, Exception) as e:
                        self.logger.warning(f"è¯»å–è¯„è®ºç¼“å­˜å¤±è´¥: {str(e)}")
                        comments = {"code": -1, "message": f"è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}", "data": []}
            except Exception as e:
                self.logger.warning(f"è·å–è¯„è®ºå¤±è´¥ï¼ˆéè‡´å‘½é”™è¯¯ï¼‰: {str(e)}")
                comments = {"code": -1, "message": str(e), "data": []}
            video_data['comments'] = comments

            # è·å–å¼¹å¹•ï¼ˆå¿½ç•¥é”™è¯¯ï¼‰
            try:
                cid = item['ugc']['first_cid']
                danmaku_path = os.path.join(video_cache_dir, 'danmaku.xml')
                if not os.path.exists(danmaku_path):
                    self.logger.debug(f"è·å–å¼¹å¹•: {video_id}")  # é™ä½æ—¥å¿—çº§åˆ«
                    danmaku = self.get_danmaku(cid)
                    if danmaku and not danmaku.startswith('<html>'): # åªåœ¨è·å–æˆåŠŸæ—¶ä¿å­˜
                        with open(danmaku_path, 'w', encoding='utf-8') as f:
                            f.write(danmaku)
                else:
                    try:
                        with open(danmaku_path, 'r', encoding='utf-8') as f:
                            danmaku = f.read()
                    except Exception as e:
                        danmaku = f"<i>è¯»å–ç¼“å­˜å¼¹å¹•å¤±è´¥: {str(e)}</i>"
            except Exception as e:
                self.logger.warning(f"è·å–å¼¹å¹•å¤±è´¥ï¼ˆéè‡´å‘½é”™è¯¯ï¼‰: {str(e)}")
                danmaku = f"<i>è·å–å¼¹å¹•å¤±è´¥: {str(e)}</i>"

            video_data['danmaku'] = danmaku
            
            try:
                # å°†è§†é¢‘ä¸‹è½½ä»»åŠ¡æ·»åŠ åˆ°é˜Ÿåˆ—
                video_path = os.path.join(video_cache_dir, 'video.mp4')
                if not os.path.exists(video_path):
                    self.logger.info(f"æ·»åŠ ä¸‹è½½ä»»åŠ¡: {title[:20]}{'...' if len(title) > 20 else ''}")
                    self.download_queue.add_task(
                        lambda: self.download_video(video_id, bvid, video_path)
                        )
            except Exception as e:
                self.logger.error(f"æ·»åŠ ä¸‹è½½ä»»åŠ¡å¤±è´¥: {str(e)}")
                
            try:
                # ä¿å­˜ä¿¡æ¯
                info_path = os.path.join(video_cache_dir, 'info.json')
                with open(info_path, 'w', encoding='utf-8') as f:
                    json.dump(video_data, f, ensure_ascii=False, indent=4)
                
                self.logger.debug(f"è§†é¢‘ä¿¡æ¯å¤„ç†å®Œæˆ: {video_id}")  # é™ä½æ—¥å¿—çº§åˆ«
                
            except Exception as e:
                self.logger.error(f"ä¿å­˜è§†é¢‘ä¿¡æ¯å¤±è´¥ [{title[:20]}...]: {str(e)}")
                raise
        except Exception as e:
            self.logger.error(f"å¤„ç†è§†é¢‘å¤±è´¥ [{title}]: {str(e)}")
            return False # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè§†é¢‘è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸

    def save_login_info(self):
        """ä¿å­˜ç™»å½•ä¿¡æ¯åˆ°ç¼“å­˜æ–‡ä»¶"""
        cache_dir = 'cache'
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        with open(os.path.join(cache_dir, 'login_info.json'), 'w', encoding='utf-8') as f:
            json.dump(self.session.cookies.get_dict(), f, ensure_ascii=False, indent=4)

    def load_login_info(self):
        """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½ç™»å½•ä¿¡æ¯ï¼Œè¿”å›æ˜¯å¦åŠ è½½æˆåŠŸ"""
        cache_dir = 'cache'
        cache_file = os.path.join(cache_dir, 'login_info.json')
        if not os.path.exists(cache_file):
            return False
            
        with open(cache_file, 'r', encoding='utf-8') as f:
            login_info = json.load(f)
            self.session.cookies.update(login_info)
            
        # éªŒè¯ç™»å½•çŠ¶æ€
        response = self.session.get("https://www.bilibili.com/")
        return response.status_code == 200

    def get_user_mid(self):
        """ä»ç¼“å­˜è·å–ç”¨æˆ·midï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¯·æ±‚è¾“å…¥å¹¶ä¿å­˜"""
        cache_dir = 'cache'
        cache_file = os.path.join(cache_dir, 'mid.txt')
        
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
            
        if not os.path.exists(cache_file):
            mid = input("è¯·è¾“å…¥ç”¨æˆ·midï¼š")
            with open(cache_file, 'w', encoding='utf-8') as f:
                f.write(mid)
        else:
            with open(cache_file, 'r', encoding='utf-8') as f:
                mid = f.read().strip()
                
        return mid

    def get_cached_data(self, force_refresh, cache_dir, cache_filename, fetch_func, *args):
        """
        é€šç”¨ç¼“å­˜æ•°æ®è·å–å‡½æ•°
        
        å‚æ•°:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
            cache_dir: ç¼“å­˜ç›®å½•
            cache_filename: ç¼“å­˜æ–‡ä»¶å
            fetch_func: è·å–æ•°æ®çš„å‡½æ•°
            args: fetch_funcçš„å‚æ•°
            
        è¿”å›:
            ç¼“å­˜çš„æ•°æ®æˆ–æ–°è·å–çš„æ•°æ®
        """
        try:
            cache_file = os.path.join(cache_dir, cache_filename)
            
            if os.path.exists(cache_file) and not force_refresh:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                data = fetch_func(*args)
                # æ£€æŸ¥APIè¿”å›æ˜¯å¦æˆåŠŸ
                if isinstance(data, dict) and data.get('code') != 0:
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {data.get('message')}")
            
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                return data
        except Exception as e:
            self.logger.error(f"è·å–æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def main(self):
        try:
            self.logger.info('å¼€å§‹æ”¶è—å¤¹ä¸‹è½½ä»»åŠ¡')
            
            # å°è¯•åŠ è½½å·²ä¿å­˜çš„ç™»å½•ä¿¡æ¯ï¼Œå¦‚æœå¤±è´¥åˆ™é‡æ–°ç™»å½•
            if not self.load_login_info():
                self.login()
                self.save_login_info()

            self.logger.info('ç™»å½•æˆåŠŸ!')

            # è·å–ç”¨æˆ·mid
            mid = self.get_user_mid()

            # é’ˆå¯¹midåˆ›å»ºç¼“å­˜ç›®å½•
            cache_dir = os.path.join(os.path.dirname(__file__), 'data', mid)
            os.makedirs(cache_dir, exist_ok=True)

            # è·å–æ”¶è—å¤¹åˆ—è¡¨ï¼Œæ·»åŠ force_refreshå‚æ•°
            force_refresh = False
            collections = self.get_cached_data(force_refresh, cache_dir, 'collections.json', 
                                             self.get_collection_list, mid)
            if not collections:
                self.logger.warning("é¦–æ¬¡è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶åˆ·æ–°...")
                force_refresh = True
                collections = self.get_cached_data(force_refresh, cache_dir, 'collections.json', 
                                                 self.get_collection_list, mid)
                if not collections:
                    raise Exception("è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥")
            
            # éå†æ”¶è—å¤¹
            for folder in collections['data']['list']:
                self.logger.info(f"æ”¶è—å¤¹: {folder['title']}")
                media_id = folder['id']
                pn = 1
                
                while True: 
                    content = self.get_cached_data(force_refresh, cache_dir, 
                                                 f'{media_id}_{pn}.json',
                                                 self.get_collection_content, 
                                                 media_id, pn)
                    
                    if not content or not content['data']['medias']:
                        break
                        
                    self.logger.info(f"å¤„ç†ç¬¬ {pn} é¡µè§†é¢‘")
                    
                    with ThreadPoolExecutor(max_workers=4) as executor:
                        futures = []
                        for media in content['data']['medias']:
                            # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
                            required_fields = ['id', 'bvid', 'title', 'cover', 'ugc']
                            if not all(field in media for field in required_fields):
                                self.logger.error(f"åª’ä½“æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {media}")
                                continue
                            
                            self.logger.info(f"å‡†å¤‡å¤„ç†è§†é¢‘: {media['title']} (id: {media['id']})")
                            future = executor.submit(self.process_video, cache_dir, media)
                            futures.append(future)
                        
                        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
                        for future in futures:
                            try:
                                future.result()
                            except Exception as e:
                                self.logger.error(f"å¤„ç†è§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    
                    self.logger.info(f"ç¬¬{pn}é¡µè§†é¢‘å¤„ç†å®Œæˆ")
                    pn += 1
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«

            # åœ¨æ‰€æœ‰æ”¶è—å¤¹å¤„ç†å®Œæˆåï¼Œç­‰å¾…ä¸‹è½½é˜Ÿåˆ—å®Œæˆ
            self.logger.info("ç­‰å¾…æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆ...")
            self.download_queue.queue.join()
            self.download_queue.stop()
            self.logger.info("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ!")
                
            self.logger.info('='*50)
            self.logger.info('ç¨‹åºæ‰§è¡Œå®Œæˆ')
            self.logger.info('='*50)
                
        except Exception as e:
            self.logger.error('ç¨‹åºæ‰§è¡Œå‡ºé”™')
            self.logger.error(str(e))
            self.logger.info('='*50)
            raise

if __name__ == "__main__":
    collector = BilibiliCollector()
    collector.main()
